{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to fck-nat. The (f)easible (c)ost (k)onfigurable NAT!</p> <ul> <li>Overpaying for AWS Managed NAT Gateways? fck-nat.</li> <li>Want to use NAT instances and stay up-to-date with the latest security patches? fck-nat.</li> <li>Want to reuse your Bastion hosts as a NAT? fck-nat.</li> </ul> <p>fck-nat offers a ready-to-use ARM and x86 based AMIs built on Amazon Linux 2 which can support up to 5Gbps burst NAT traffic on a t4g.nano instance. How does that compare to a Managed NAT Gateway?</p> <p>Hourly rates:</p> <ul> <li>Managed NAT Gateway hourly: $0.045</li> <li>t4g.nano hourly: $0.0042</li> </ul> <p>Per GB rates:</p> <ul> <li>Managed NAT Gateway per GB: $0.045</li> <li>fck-nat per GB: $0.00</li> </ul> <p>Sitting idle, fck-nat costs 10% of a Managed NAT Gateway. In practice, the savings are even greater.</p> <p>\"But what about AWS' NAT Instance AMI?\"</p> <p>The official AWS supported NAT Instance AMI hasn't been updates since 2018, is still running Amazon Linux 1 which is now EOL, and has no ARM support, meaning it can't be deployed on EC2's most cost effective instance types. fck-nat.</p> <p>\"When would I want to use a Managed NAT Gateway instead of fck-nat?\"</p> <p>AWS limits outgoing internet bandwidth on EC2 instances to 5Gbps. This means that the highest bandwidth that fck-nat can support (while remaining cost-effective) is 5Gbps. This is enough to cover a very broad set of use cases, but if you need additional bandwidth, you should use Managed NAT Gateway. If AWS were to lift the limit on internet egress bandwidth from EC2, you could cost-effectively operate fck-nat at speeds up to 25Gbps, but you wouldn't need Managed NAT Gateway then would you? fck-nat.</p> <p>Read more about EC2 bandwidth limits here</p> <p>Additionally, if you have an allergy to non-managed services, fck-nat may not be for you. Although fck-nat supports a high-availability mode, it is not completely immune to outages (albeit very rare). If your workload requires five 9s of uptime, then Managed NAT Gateway is likely a better option for you.</p>"},{"location":"#using-fck-nat","title":"Using fck-nat","text":"<p>The primary objective of fck-nat is to make deploying your own NAT instances as easy, secure, and configurable as possible. While fck-nat strives to provide out-of-the-box options and guides that work for most people, everyone's requirements are different. Where fck-nat can't provide a ready-to-use solution, we try to offer you all the toggles you need to get up and running yourself with as little headache as possible. We follow the \"batteries included, but swappable\" philosophy.</p>"},{"location":"#getting-a-fck-nat-ami","title":"Getting a fck-nat AMI","text":"<p>fck-nat provides public AMIs in both arm64 and x86_64 flavors built on top of Amazon Linux 2. If you would rather use a different base image or host the AMI yourself, you can build your own AMI.</p>"},{"location":"#the-public-fck-nat-amis","title":"The public fck-nat AMIs","text":"<p>fck-nat currently provides public AMIs in most regions. You can see the full list in <code>packer/fck-nat-public-all-regions.pkrvars.hcl</code>. While arm64 images are the most cost effective, x86_64 images are also available. You can get view the available fck-nat AMIs with the following query:</p> <pre><code># Amazon Linux 2 based AMIs\naws ec2 describe-images --owners 568608671756 --filters 'Name=name,Values=fck-nat-al2023-*'\n</code></pre>"},{"location":"#building-your-own-fck-nat-ami","title":"Building your own fck-nat AMI","text":"<p>fck-nat images are built using Packer. You can find the Packer files we use to build the public images inside the <code>packer</code> folder. Our Packer configuration uses variables extensively, allowing you to customize your base image, build region, architecture, etc. If the publicly available AMIs don't suit your needs, or you would prefer to host the AMIs yourself, you can create your own <code>pkrvars.hcl</code> file and build your own AMI.</p> <pre><code>packer build -var-file=\"your-var-file.pkrvars.hcl\" ./packer/fck-nat.pkr.hcl\n</code></pre>"},{"location":"#installing-fck-nat-from-the-rpm","title":"Installing fck-nat from the RPM","text":"<p>If you have an existing AMI and you want to install fck-nat on it, you can get the <code>.rpm</code> build of fck-nat from the Releases page.</p>"},{"location":"#using-your-fck-nat-ami","title":"Using your fck-nat AMI","text":"<p>An AMI isn't the only thing you'll need to get up and running with fck-nat. There's a few options which need to be configured in order to route traffic to your NAT. Namely, you must:</p> <ol> <li>Configure a security group for your fck-nat instance</li> <li>Disable source/destination checks</li> <li>Update your VPC route table</li> </ol> <p>Some tools can accomplish this for you, others cannot. Check the \"Deploying\" section for more information about deploying fck-nat with your favorite infrastructure-as-code tool.</p>"},{"location":"configuration/","title":"fck-nat Configuration","text":""},{"location":"configuration/#configuration-file","title":"Configuration file","text":"<p>Upon starting, fck-nat evaluates a configuration file describing how the instance should behave as well as what features shall be enabled. To configure fck-nat, ensure a file <code>/etc/fck-nat.conf</code> exists with your configuration. fck-nat requires the service to be restarted by running <code>service fck-nat-resart</code>. In most implementations this configuration is passed only once via EC2's user data.</p> <p>The following describes available options: | name                    | description | | ----------------------- | ----------- | | <code>eni_id</code>                | The ID of the Elastic Network Interface to attach to the instance and use as a consistent endpoint to send traffic to fck nat. This is required when using high-availability mode. | | <code>eip_id</code>                | The ID of an Elastic IP to be attached to the public network interface. This ensures the NAT gateway public traffic is always routed through the same public IP address. | | <code>cwagent_enabled</code>       | If set, enables Cloudwatch agent and forward instance metrics to Cloudwatch. Requires <code>cwagent_cfg_param_name</code> to be set. | | <code>cwagent_cfg_param_name</code> | The name of the SSM Parameter holding the Cloudwatch agent configuration and which the agent shall pull from. Requires <code>cwagent_enabled</code> to be set. |</p>"},{"location":"deploying/","title":"Deploying fck-nat","text":"<p>The most well-supported way to deploy fck-nat with all of its features available out of the box is via CDK. If you're using another Infrastructure-as-code provider, you can still deploy a basic NAT instance with fck-nat, but it is more intensive to support some of fck-nat's additional features.</p> <p>Notably missing at the moment is a Terraform module. If you're using Terraform and would like to leverage fck-nat, please +1 this issue: Create a fck-nat Terraform module</p>"},{"location":"deploying/#cdk","title":"CDK","text":"<p>fck-nat provides an official CDK module which supports all of fck-nat's features (namely high-availability mode) out-of-the-box. The CDK module is currently available both in Typescript and Python. You can find detailed documentation on Construct Hub. Here's an example use of the CDK construct in Typescript:</p> <pre><code>const natGatewayProvier = new FckNatInstanceProvider({\n    instanceType: InstanceType.of(InstanceClass.T4G, InstanceSize.MICRO),\n});\nconst vpc = new Vpc(this, 'vpc', {\n    natGatewayProvider,\n});\nnatGatewayProvider.securityGroup.addIngressRule(Peer.ipv4(vpc.vpcCidrBlock), Port.allTraffic());\n</code></pre> <p>That's it! This will deploy your VPC using fck-nat as your NAT provider in high availability mode. This includes all necessary routing configurations and deploys fck-nat in an Autoscaling group to ensure that a new instance is brought up automatically in case the NAT instance is terminated.</p> <p>You can also deploy fck-nat in non-HA mode using CDK's built-in <code>NatInstanceProvider</code> like so:</p> <pre><code>const natGatewayProvider = new NatInstanceProvider({\n    instanceType: InstanceType.of(InstanceClass.T4G, InstanceSize.MICRO),\n    machineImage: new LookupMachineImage({\n        name: 'fck-nat-al2023-*-arm64-ebs',\n        owners: ['568608671756'],\n    })\n})\nconst vpc = new Vpc(this, 'vpc', {\n    natGatewayProvider,\n});\nnatGatewayProvider.securityGroup.addIngressRule(Peer.ipv4(vpc.vpcCidrBlock), Port.allTraffic());\n</code></pre> <p>Read more about the <code>NatInstanceProvider</code> construct</p>"},{"location":"deploying/#terraform","title":"Terraform","text":"<p>Doriann Corlou\u00ebr (RaJiska) maintains the official fck-nat Terraform module over at terraform-aws-fck-nat. Below is a sample of how to use that module and full documentation can be found on the Terraform Registry</p> <pre><code>module \"fck-nat\" {\n  source = \"RaJiska/fck-nat/aws\"\n\n  name                 = \"my-fck-nat\"\n  vpc_id               = \"vpc-abc1234\"\n  subnet_id            = \"subnet-abc1234\"\n  # ha_mode              = true                 # Enables high-availability mode\n  # eip_allocation_ids   = [\"eipalloc-abc1234\"] # Allocation ID of an existing EIP\n  # use_cloudwatch_agent = true                 # Enables Cloudwatch agent and have metrics reported\n\n  update_route_tables = true\n  route_tables_ids = {\n    \"your-rtb-name-A\" = \"rtb-abc1234Foo\"\n    \"your-rtb-name-B\" = \"rtb-abc1234Bar\"\n  }\n}\n</code></pre> <p>It is also possible to configure fck-nat with out-of-the-box Terraform modules, but you may not be able to leverage all of fck-nat's features.</p> <pre><code>data \"aws_ami\" \"fck_nat\" {\n  filter {\n    name   = \"name\"\n    values = [\"fck-nat-al2023-*\"]\n  }\n\n  filter {\n    name   = \"architecture\"\n    values = [\"arm64\"]\n  }\n\n  owners      = [\"568608671756\"]\n  most_recent = true\n}\n\nresource \"aws_network_interface\" \"fck-nat-if\" {\n  subnet_id       = aws_subnet.subnet_public.id\n  security_groups = [aws_default_security_group.default_security_group.id]\n\n  source_dest_check = false\n}\n\nresource \"aws_instance\" \"fck-nat\" {                                                   \n  ami           = data.aws_ami.fck_nat.id\n  instance_type = \"t4g.nano\"\n\n  network_interface {\n    network_interface_id = aws_network_interface.fck-nat-if.id\n    device_index         = 0\n  }                                                                              \n}\n</code></pre>"},{"location":"deploying/#cloudformation","title":"Cloudformation","text":"<p>For brevity, this document assumes you already have a VPC with public and private subnets defined in your Cloudformation template. This example template provisions the minimum resources required to connect fck-nat in your VPC. This is a good option for those that have an existing VPC and NAT Gateway and are looking to switch over. </p> <ol> <li>A security group allowing ingress traffic from within the VPC and egress out to the internet</li> <li>A auto scaling group that creates an EC2 instance using the fck-nat AMI</li> <li>A route in the private subnet route table directing traffic to the fck-nat instance.</li> </ol> <p>This snippet assumes the following resources are already defined:</p> <ol> <li><code>VPC</code>: An <code>AWS::EC2::VPC</code> resource.</li> <li><code>PublicSubnet</code>: An <code>AWS::EC2::Subnet</code> which has an <code>AWS::EC2::InternetGateway</code> attached.</li> <li><code>PrivateSubnetRouteTable</code>: An <code>AWS::EC2::RouteTable</code> with an <code>AWS::EC2::SubnetRouteTableAssociation</code> to a <code>AWS::EC2::Subnet</code></li> </ol> <p>Steps to deploy:</p> <ol> <li>Paste your VPC ID, public subnet ID, and CIDR block into the parameters. Change the ImageId based on the region fck-nat is deployed to.</li> <li>Ensure that your public subnet has <code>Enable auto-assign public IPv4 address</code> turned on. This can be found in the Console at <code>VPC &gt; Subnets &gt; Edit subnet settings &gt; Auto-assign IP settings</code>.</li> <li>Deploy with cloudformation <code>aws cloudformation deploy --force-upload --capabilities CAPABILITY_IAM --template-file template.yml --stack-name FckNat</code></li> <li>Add the default route to your route table on the subnet. It is best to do this manually so you can do a seamless cut over from your existing nat gateway. Go to <code>VPC &gt; Route Tables &gt; Private route table &gt; Routes &gt; Edit Routes</code> Add a 0.0.0.0/0 route pointing to the network interface.</li> </ol> <pre><code>Parameters:\n  vpc:\n    Type: String\n    Default: \"vpc-121212121212121212\"\n  subnet:\n    Type: String\n    Default: \"subnet-121212121212121212\"\n  CIDR:\n    Type: String\n    Default: \"10.0.0.0/16\"\n\nResources:\n  FckNatInterface:\n    Type: AWS::EC2::NetworkInterface\n    Properties:\n      SubnetId: !Sub \"${subnet}\"\n      GroupSet:\n        - Fn::GetAtt:\n            - NatSecurityGroup\n            - GroupId\n      SourceDestCheck: false\n\n  FckNatAsgInstanceProfile:\n    Type: AWS::IAM::InstanceProfile\n    Properties:\n      Roles:\n        - Ref: NatRole\n\n  FckNatAsgLaunchConfig:\n    Type: AWS::AutoScaling::LaunchConfiguration\n    Properties:\n      ImageId: ami-05b6d5a2e26f13c93\n      InstanceType: t4g.nano\n      IamInstanceProfile:\n        Ref: FckNatAsgInstanceProfile\n      SecurityGroups:\n        - Fn::GetAtt:\n            - NatSecurityGroup\n            - GroupId\n      UserData:\n        Fn::Base64:\n          Fn::Join:\n            - \"\"\n            - - |-\n                #!/bin/bash\n                echo \"eni_id=\n              - Ref: FckNatInterface\n              - |-\n                \" &gt;&gt; /etc/fck-nat.conf\n                service fck-nat restart\n    DependsOn:\n      - NatRole\n\n  FckNatAsg:\n    Type: AWS::AutoScaling::AutoScalingGroup\n    Properties:\n      MaxSize: \"1\"\n      MinSize: \"1\"\n      DesiredCapacity: \"1\"\n      LaunchConfigurationName:\n        Ref: FckNatAsgLaunchConfig\n      VPCZoneIdentifier:\n        - !Sub \"${subnet}\"\n    UpdatePolicy:\n      AutoScalingScheduledAction:\n        IgnoreUnmodifiedGroupSizeProperties: true\n\n  NatSecurityGroup:\n    Type: AWS::EC2::SecurityGroup\n    Properties:\n      GroupDescription: Security Group for NAT\n      SecurityGroupIngress: \n        - CidrIp: !Sub \"${CIDR}\"\n          IpProtocol: \"-1\"\n      SecurityGroupEgress:\n        - CidrIp: 0.0.0.0/0\n          Description: Allow all outbound traffic by default\n          IpProtocol: \"-1\"\n      VpcId: !Sub \"${vpc}\" \n\n  NatRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        Statement:\n          - Action: sts:AssumeRole\n            Effect: Allow\n            Principal:\n              Service: ec2.amazonaws.com\n        Version: \"2012-10-17\"\n      Policies:\n        - PolicyDocument:\n            Statement:\n              - Action:\n                  - ec2:AttachNetworkInterface\n                  - ec2:ModifyNetworkInterfaceAttribute\n                Effect: Allow\n                Resource: \"*\"\n            Version: \"2012-10-17\"\n          PolicyName: attachNatEniPolicy\n        - PolicyDocument:\n            Statement:\n              - Action:\n                  - ec2:AssociateAddress\n                  - ec2:DisassociateAddress\n                Effect: Allow\n                Resource: \"*\"\n            Version: \"2012-10-17\"\n          PolicyName: associateNatAddressPolicy\n</code></pre>"},{"location":"deploying/#manual-web-console","title":"Manual - Web Console","text":"<p>The following instructions can be used to deploy the fck-nat AMI manually. **Summary: **  1. Launch fck-nat AMI 2. Modify ENI to disable source/dest check 3. Modify the private route table, default route to fck-nat target 4. Validate</p> <p>NOTE: The following example uses fck-nat AMI version 1.2.0 for arm64 on t4g.nano.</p>"},{"location":"deploying/#ec2-instance-launch","title":"EC2 Instance Launch","text":"<ol> <li>Visit the EC2 service in your preferred region: EC2 Link</li> <li>Click Launch Instances </li> <li>Give the instance a name </li> <li>Search for AMIs owned by \"568608671756\"    </li> <li>Select the ARM64 1.2.0 fck-nat AMI </li> <li>Select Instance Type t4g.nano </li> <li>Modify Network Settings  </li> <li>Select VPC  </li> <li>Place in public subnet, ensure Public IP is assigned  </li> <li>Attached Security group that permits        inbound: entire VPC CIDR inbound, all traffic        outbound: 0.0.0.0/0, all traffic </li> <li>Leave Storage at 2GB </li> <li>Review and launch </li> </ol> <p>Wait for Launch</p>"},{"location":"deploying/#modify-ec2-network-interface","title":"Modify EC2 Network Interface","text":"<p>We must modify the ENI attached to the newly launched instance to disable source/destination checks, this allows us to route through (actually hairpinning) the instance. 1. Click on the ENI of the instance  2. Select ENI, Click Actions -&gt; Change source/dest. check  3. Disable Source/Dest check and Save </p>"},{"location":"deploying/#modify-vpc-routing-table","title":"Modify VPC Routing Table","text":"<p>The VPC routing table associated with your private subnets must be modified to route traffic matching the default route to the new fck-nat instance. 1.  Open the VPC Service, Route Tables  2. Open the private route table, edit routes  3. Add a default route, target: fck-nat instance </p>"},{"location":"deploying/#validate","title":"Validate","text":"<p>Log into an instance in a private subnet and validate the external IP is the public IP assigned to your fck-nat instance.  </p> <p> </p>"},{"location":"features/","title":"fck-nat Features","text":""},{"location":"features/#high-availability-mode","title":"High-availability Mode","text":"<p>fck-nat can operate on a single instance, or withing an autoscaling group for improved availability. When running in an autoscaling group, fck-nat can be configured to always attach a specific ENI at start-up, allowing fck-nat to maintain a consistent internal-facing IP address. Additionally, it is also possible to configure an already allocated EIP address that would be carried through instance refreshs.</p> <p>Those features are controlled by <code>eni_id</code> and <code>eip_id</code> directive in the configuration file.  </p> <p>IAM requirements: <code>ec2:AttachNetworkInterface</code>, <code>ec2:ModifyNetworkInterfaceAttribute</code> on <code>*</code> for ha-mode, plus <code>ec2:AssociateAddress</code>, <code>ec2:DisassociateAddress</code> on <code>*</code> when using a static EIP.</p>"},{"location":"features/#metrics","title":"Metrics","text":"<p>One of the objectives of fck-nat is to offer as close as possible metric parity with Managed NAT Gateway. While the project supports various metrics similar to the managed NAT Gateway via Cloudwatch agent, each provider is responsible for passing their configuration to the agent via fck-nat's <code>cwagent_enabled</code>, and <code>cwagent_cfg_param_name</code> directives within its configuration file.</p> <p>As an example, you might use the following configuration file which have Cloudwatch agent report most of metrics provided in the managed NAT Gateway:</p> <pre><code>{\n  \"agent\": {\n    \"metrics_collection_interval\": 60,\n    \"run_as_user\": \"root\",\n    \"usage_data\": false\n  },\n  \"metrics\": {\n    \"namespace\": \"fck-nat\",\n    \"metrics_collected\": {\n      \"net\": {\n        \"resources\": [\"eth0\", \"eth1\"],\n        \"measurement\": [\n          { \"name\": \"bytes_recv\", \"rename\": \"BytesIn\",  \"unit\": \"Bytes\" },\n          { \"name\": \"bytes_sent\", \"rename\": \"BytesOut\",  \"unit\": \"Bytes\" },\n          { \"name\": \"packets_sent\", \"rename\": \"PacketsOutCount\",  \"unit\": \"Count\" },\n          { \"name\": \"packets_recv\", \"rename\": \"PacketsInCount\",  \"unit\": \"Count\" },\n          { \"name\": \"drop_in\", \"rename\": \"PacketsDropInCount\",  \"unit\": \"Count\" },\n          { \"name\": \"drop_out\", \"rename\": \"PacketsDropOutCount\",  \"unit\": \"Count\" }\n        ]\n      },\n      \"netstat\": {\n        \"measurement\": [\n          { \"name\": \"tcp_syn_sent\", \"rename\": \"ConnectionAttemptOutCount\",  \"unit\": \"Count\" },\n          { \"name\": \"tcp_syn_recv\", \"rename\": \"ConnectionAttemptInCount\",  \"unit\": \"Count\" },\n          { \"name\": \"tcp_established\", \"rename\": \"ConnectionEstablishedCount\",  \"unit\": \"Count\" }\n        ]\n      },\n      \"ethtool\": {\n        \"interface_include\": [\"eth0\", \"eth1\"],\n        \"metrics_include\": [\n          \"bw_in_allowance_exceeded\",\n          \"bw_out_allowance_exceeded\",\n          \"conntrack_allowance_exceeded\",\n          \"pps_allowance_exceeded\"\n        ]\n      },\n      \"mem\": {\n        \"measurement\": [\n          { \"name\": \"used_percent\", \"rename\": \"MemoryUsed\",  \"unit\": \"Percent\" }\n        ]\n      }\n    },\n    \"append_dimensions\": {\n      \"InstanceId\": \"$${aws:InstanceId}\"\n    }\n  }\n}\n</code></pre> <p>Ensure you are aware of Cloudwatch metrics costs before enabling Cloudwatch agent. The above configuration would cost you about $17/monthly, excluding free tier.  </p> <p>IAM requirements: <code>ssm:GetParameter</code> on the SSM Parameter ARN, and <code>cloudwatch:PutMetricData</code> on <code>*</code>.</p>"}]}