{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to fck-nat. The (f)easible (c)ost (k)onfigurable NAT!</p> <ul> <li>Overpaying for AWS Managed NAT Gateways? fck-nat.</li> <li>Want to use NAT instances and stay up-to-date with the latest security patches? fck-nat.</li> <li>Want to reuse your Bastion hosts as a NAT? fck-nat.</li> </ul> <p>fck-nat offers a ready-to-use ARM and x86 based AMIs built on Amazon Linux 2023 which can support up to 5Gbps burst NAT traffic on a t4g.nano instance. How does that compare to a Managed NAT Gateway?</p> <p>Hourly rates:</p> <ul> <li>Managed NAT Gateway hourly: $0.045</li> <li>t4g.nano hourly: $0.0042</li> </ul> <p>Per GB rates:</p> <ul> <li>Managed NAT Gateway per GB: $0.045</li> <li>fck-nat per GB: $0.00</li> </ul> <p>Sitting idle, fck-nat costs 10% of a Managed NAT Gateway. In practice, the savings are even greater.</p> <p>\"But what about AWS' NAT Instance AMI?\"</p> <p>The official AWS supported NAT Instance AMI hasn't been updates since 2018, is still running Amazon Linux 1 which is now EOL, and has no ARM support, meaning it can't be deployed on EC2's most cost effective instance types. fck-nat.</p> <p>\"When would I want to use a Managed NAT Gateway instead of fck-nat?\"</p> <p>AWS limits outgoing internet bandwidth on EC2 instances to 5Gbps. This means that the highest bandwidth that fck-nat can support (while remaining cost-effective) is 5Gbps. This is enough to cover a very broad set of use cases, but if you need additional bandwidth, you should use Managed NAT Gateway. If AWS were to lift the limit on internet egress bandwidth from EC2, you could cost-effectively operate fck-nat at speeds up to 25Gbps, but you wouldn't need Managed NAT Gateway then would you? fck-nat.</p> <p>Read more about EC2 bandwidth limits here</p> <p>Additionally, if you have an allergy to non-managed services, fck-nat may not be for you. Although fck-nat supports a high-availability mode, it is not completely immune to outages (albeit very rare). If your workload requires five 9s of uptime, then Managed NAT Gateway is likely a better option for you.</p>"},{"location":"#using-fck-nat","title":"Using fck-nat","text":"<p>The primary objective of fck-nat is to make deploying your own NAT instances as easy, secure, and configurable as possible. While fck-nat strives to provide out-of-the-box options and guides that work for most people, everyone's requirements are different. Where fck-nat can't provide a ready-to-use solution, we try to offer you all the toggles you need to get up and running yourself with as little headache as possible. We follow the \"batteries included, but swappable\" philosophy.</p>"},{"location":"#getting-a-fck-nat-ami","title":"Getting a fck-nat AMI","text":"<p>fck-nat provides public AMIs in both arm64 and x86_64 flavors built on top of Amazon Linux 2023. If you would rather use a different base image or host the AMI yourself, you can build your own AMI.</p>"},{"location":"#the-public-fck-nat-amis","title":"The public fck-nat AMIs","text":"<p>fck-nat currently provides public AMIs in most regions. You can see the full list in <code>packer/fck-nat-public-all-regions.pkrvars.hcl</code>. While arm64 images are the most cost effective, x86_64 images are also available. You can get view the available fck-nat AMIs with the following query:</p> <pre><code># Amazon Linux 2023 based AMIs\naws ec2 describe-images --owners 568608671756 --filters 'Name=name,Values=fck-nat-al2023-*'\n</code></pre>"},{"location":"#building-your-own-fck-nat-ami","title":"Building your own fck-nat AMI","text":"<p>fck-nat images are built using Packer. You can find the Packer files we use to build the public images inside the <code>packer</code> folder. Our Packer configuration uses variables extensively, allowing you to customize your base image, build region, architecture, etc. If the publicly available AMIs don't suit your needs, or you would prefer to host the AMIs yourself, you can create your own <code>pkrvars.hcl</code> file and build your own AMI.</p> <pre><code>packer build -var-file=\"your-var-file.pkrvars.hcl\" ./packer/fck-nat.pkr.hcl\n</code></pre>"},{"location":"#installing-fck-nat-from-the-rpm","title":"Installing fck-nat from the RPM","text":"<p>If you have an existing AMI and you want to install fck-nat on it, you can get the <code>.rpm</code> build of fck-nat from the Releases page.</p>"},{"location":"#using-your-fck-nat-ami","title":"Using your fck-nat AMI","text":"<p>An AMI isn't the only thing you'll need to get up and running with fck-nat. There's a few options which need to be configured in order to route traffic to your NAT. Namely, you must:</p> <ol> <li>Configure a security group for your fck-nat instance</li> <li>Disable source/destination checks</li> <li>Update your VPC route table</li> </ol> <p>Some tools can accomplish this for you, others cannot. Check the Deployment page for more information about deploying fck-nat with your favorite infrastructure-as-code tool.</p>"},{"location":"choosing_an_instance_size/","title":"Choosing an Instance Size","text":"<p>It can be a bit difficult to understand what instance size is best for your needs when considering a fck-nat instance, but if you keep in mind a few key rules, the decision should be relatively straightforward. We also include some baseline recommendations below.</p> <p>The rules of EC2 to internet networking:</p> <ol> <li>Most instances offer bandwidth \"Up to\" a certain amount. This is their burst capacity. Their baseline is    signigicantly smaller. The baseline value is available via the EC2 <code>describe-instance-types</code> API.</li> <li>Instances with fewer than 32 vCPUs are limited to a maximum of 5Gbps egress to the internet.</li> <li>Instances with &gt;=32 vCPUs are allowed 50% their baseline bandwidth out to the internet.</li> </ol> <p>Alright, now that we have those rules down, what's the best option for you? It's suggested that you read all of the sections below before jumping to the one you need because there's a lot of good information spread throughout that could help in your decision making, but here's a summary table:</p> Bandwidth Instance type Price per Month 32Mbps t4g.nano $3.06 64Mbps t3.micro $7.59 1.6Gbps c6gn.medium $32.81 3.125Gbps c7gn.medium $48.25 5Gbps c7gn.large $132.20 25Gbps r6in.8xlarge $1074.56 50Gbps c7gn.8xlarge $1457.66 <p>Yes, there's some big jumps there. No, there's not really any sensible option in between.</p>"},{"location":"choosing_an_instance_size/#i-want-to-spend-less-than-10-per-month-on-a-nat-solution","title":"I want to spend less than $10 per month on a NAT solution","text":"<p>For you my friend, we have the <code>t4g.nano</code>. Not only is the <code>t4g.nano</code> the least expensive option out of all instance types, it also has the highest Gbps/dollar ratio of all the options under $10! The <code>t4g.nano</code> supports a burst bandwidth of up to 5Gbps and a sustained bandwidth of 32Mbps for $3.06/month.</p> <p>If you're looking for an option that's a little more expensive but has a higher sustained bandwidth, the <code>t3.micro</code> is $7.59/month and supports a sustained bandwidth of 64Mbps.</p>"},{"location":"choosing_an_instance_size/#i-need-at-least-1gbps-sustained-egress","title":"I need at least 1Gbps sustained egress","text":"<p>You have two really good options here. The <code>c6gn.medium</code> offers a sustained bandwidth of 1.6 Gbps for $32.81/month which is the lowest price available for any instance supporting &gt;1Gbps egress.</p> <p>If you're willing to spend a little more, you can get the Rolls Royce of NAT instances, the <code>c7gn.medium</code>. The <code>c7gn.medium</code> supports a whopping 3.125Gbps sustained bandwidth and boasts the highest Gbps/dollar ration out of any instance type in AWS for $48.25/month</p>"},{"location":"choosing_an_instance_size/#how-about-5gbps-sustained-egress","title":"How about 5Gbps sustained egress?","text":"<p>If you want to hit the max (at &lt;32vCPUs) sustained capacity of 5Gbps out to the internet then your best option is the <code>c7gn.large</code> which offers 5Gbps sustained for $132.20/month.</p>"},{"location":"choosing_an_instance_size/#i-need-more","title":"I need more","text":"<p>Remember, once you're looking to top 5Gbps, you have to look at instance types with at least 32 vCPUs. This means that you're looking at a significant price jump. At this point, it is worthwhile considering sticking to NAT Gateway, but there's definitely high total throughput cases which warrant rolling your own NAT at this scale.</p> <p>The lowest priced instance offering more than 5Gbps egress is the <code>c6g.8xlarge</code> for $794.42/month and offering...6Gbps. Once you start getting to this level though, the scaling function actually becomes really straightforward because AWS offers dedicated networking at known increments: 12Gbps (like the <code>c6g.8xlarge</code> up there), 25Gbps, 50Gbps, and 100Gbps. Remember, at &gt;=32vCPUs you're only getting 50% egress bandwidth so the effective values are really 6Gbps, 12.5Gbps, 25Gbps, and 50Gbps</p> <p>Here's the instance types offering the best value at each bandwidth level:</p> Bandwidth Instance type Price per Month Price per Month per Gbps 32Mbps t4g.nano $    3.06 $   95.63 64Mbps t3.micro $    7.59 $  118.59 1.6Gbps c6gn.medium $   32.81 $   20.51 3.125Gbps c7gn.medium $   48.25 $   15.44 5Gbps c7gn.large $  132.20 $   26.44 6Gbps c6g.8xlarge $  794.42 $ 132.40 12.5Gbps m5n.8xlarge $ 1510.37 $ 120.83 25Gbps r6in.8xlarge $ 1074.56 $   42.98 50Gbps c7gn.8xlarge $ 1457.66 $   29.15 <p>As you can see, 6Gbps and 12.5Gbps are simply not economical options when compared to the best 5Gbps and 25Gbps options. So you're effectively looking at jumping straight from 5Gbps to 25Gbps if you need higher sustained bandwidth.</p> How were these values calculated? <p>Through some pain, effort, and a lot of <code>jq</code> you can produce the source data on your own and perform your own analysis on instance types. The scripts below will pull network bandwidth information from the EC2 API and pricing information from the pricing API then combine them along with a <code>max_egress</code> value that takes into account the rules above and a <code>ratio</code> value which is effectively Gbps per dollar and is used as a measurement of \"value\"</p> <p>You can find the scripts below as well as the most recent output to run your own analysis on in the  <code>docs/pricing_analysis</code> folder</p> <pre><code>aws ec2 describe-instance-types \\\n    --output json \\\n| jq '.InstanceTypes[] | { (.InstanceType): { vcpus: .VCpuInfo.DefaultVCpus, baseline: .NetworkInfo.NetworkCards[0].BaselineBandwidthInGbps, burst: .NetworkInfo.NetworkPerformance}}' \\\n| jq -s add &gt; instance-networking.json\n\n\naws pricing get-products \\\n    --service-code AmazonEC2 \\\n    --filters \"Type=TERM_MATCH,Field=location,Value=US East (N. Virginia)\" \\\n    --region us-east-1 \\\n| jq -rc '.PriceList[]' \\\n| jq -rc 'select(.product.productFamily==\"Compute Instance\")' \\\n| jq -r '{ (.product.attributes.instanceType): { price: (.terms.OnDemand[].priceDimensions[].pricePerUnit.USD | tonumber) }}' \\\n| jq -s add &gt; instance-pricing.json\n\njq -s '.[0] * .[1]' instance-pricing.json instance-networking.json \\\n| jq 'with_entries(select(.value | has(\"baseline\") and has(\"price\") and .price &gt; 0.0))' \\\n| jq 'to_entries | map(.value |= . + {max_egress: (if .vcpus &lt; 32 then ([.baseline, 5.0] | min) else .baseline / 2 end) }) | map(.value |= . + {ratio: (.max_egress / (.price | tonumber)), price_monthly: (.price * 730)}) | sort_by(.value.ratio) | from_entries' &gt; instance-merged.json\n</code></pre>"},{"location":"configuration/","title":"fck-nat Configuration","text":""},{"location":"configuration/#configuration-file","title":"Configuration File","text":"<p>Upon starting, fck-nat evaluates a configuration file describing how the instance should behave as well as what features shall be enabled. To configure fck-nat, ensure a file <code>/etc/fck-nat.conf</code> exists with your configuration. fck-nat requires the service to be restarted by running <code>systemctl restart fck-nat.service</code>. In most implementations this configuration is passed only once via EC2's user data.</p> <p>The following describes available options:</p> Name Description <code>eni_id</code> The ID of the Elastic Network Interface to attach to the instance and use as a consistent endpoint to send traffic to fck nat. This is required when using high-availability mode. <code>eip_id</code> The ID of an Elastic IP to be attached to the public network interface. This ensures the NAT gateway public traffic is always routed through the same public IP address. <code>cwagent_enabled</code> If set, enables Cloudwatch agent and forward instance metrics to Cloudwatch. Requires <code>cwagent_cfg_param_name</code> to be set. <code>cwagent_cfg_param_name</code> The name of the SSM Parameter holding the Cloudwatch agent configuration and which the agent shall pull from. Requires <code>cwagent_enabled</code> to be set. <code>ip_local_port_range</code> Overrides Linux's <code>net.ipv4.ip_local_port_range</code> sysctl for ephemeral source ports used by SNAT. Provide as two space\u2011separated integers <code>low high</code> (e.g., <code>1024 65535</code>). Useful to expand the ephemeral port range and reduce NAT port exhaustion and collisions. <code>nf_conntrack_max</code> Overrides Linux's <code>net.netfilter.nf_conntrack_max</code> sysctl to set the maximum number of concurrently tracked connections. Provide as an integer (e.g., <code>262144</code>). Increasing this can help high-connection workloads but consumes more memory; monitor conntrack metrics and AWS security group connection tracking quotas."},{"location":"configuration/#iam-requirements","title":"IAM Requirements","text":"<p>Certain features of fck-nat require the role attached to the instance to have permissions for certain AWS API operations. The table below details the current permission requirements for various features:</p> Feature Required Permissions HA-mode (<code>eni_id</code>) <code>ec2:AttachNetworkInterface, ec2:ModifyNetworkInterfaceAttribute</code> Static IP (<code>eip_id</code>) <code>ec2:AssociateAddress, ec2:DisassociateAddress</code> Cloudwatch Agent (<code>cwagent_enabled</code>) Managed Policy: <code>CloudWatchAgentServerPolicy</code> and <code>ssm:GetParameter</code> SSM Agent (installed by default, IAM role required to use) Managed Policy: <code>AmazonSSMManagedEC2InstanceDefaultPolicy</code>"},{"location":"deploying/","title":"Deploying fck-nat","text":"<p>The most well-supported way to deploy fck-nat with all of its features available out of the box is via CDK. If you're using another Infrastructure-as-code provider, you can still deploy a basic NAT instance with fck-nat, but it is more intensive to support some of fck-nat's additional features.</p>"},{"location":"deploying/#cdk","title":"CDK","text":"<p>fck-nat provides an official CDK module which supports all of fck-nat's features (namely high-availability mode) out-of-the-box. The CDK module is currently available both in Typescript and Python. You can find detailed documentation on Construct Hub. Here's an example use of the CDK construct in Typescript:</p> <pre><code>const natGatewayProvider = new FckNatInstanceProvider({\n    instanceType: InstanceType.of(InstanceClass.T4G, InstanceSize.NANO),\n});\nconst vpc = new Vpc(this, 'vpc', {\n    natGatewayProvider,\n});\nnatGatewayProvider.securityGroup.addIngressRule(Peer.ipv4(vpc.vpcCidrBlock), Port.allTraffic());\n</code></pre> <p>That's it! This will deploy your VPC using fck-nat as your NAT provider in high availability mode. This includes all necessary routing configurations and deploys fck-nat in an Autoscaling group to ensure that a new instance is brought up automatically in case the NAT instance is terminated.</p> <p>You can also deploy fck-nat in non-HA mode using CDK's built-in <code>NatInstanceProvider</code> like so:</p> <pre><code>const natGatewayProvider = new NatInstanceProviderV2({\n    instanceType: InstanceType.of(InstanceClass.T4G, InstanceSize.NANO),\n    machineImage: new LookupMachineImage({\n        name: 'fck-nat-al2023-*-arm64-ebs',\n        owners: ['568608671756'],\n    })\n})\nconst vpc = new Vpc(this, 'vpc', {\n    natGatewayProvider,\n});\nnatGatewayProvider.securityGroup.addIngressRule(Peer.ipv4(vpc.vpcCidrBlock), Port.allTraffic());\n</code></pre> <p>Read more about the <code>NatInstanceProvider</code> construct</p>"},{"location":"deploying/#terraform","title":"Terraform","text":"<p>Doriann Corlou\u00ebr (RaJiska) maintains the official fck-nat Terraform module over at terraform-aws-fck-nat. Below is a sample of how to use that module and full documentation can be found on the Terraform Registry</p> <pre><code>module \"fck-nat\" {\n  source = \"RaJiska/fck-nat/aws\"\n\n  name                 = \"my-fck-nat\"\n  vpc_id               = \"vpc-abc1234\"\n  subnet_id            = \"subnet-abc1234\"\n  # ha_mode              = true                 # Enables high-availability mode\n  # eip_allocation_ids   = [\"eipalloc-abc1234\"] # Allocation ID of an existing EIP\n  # use_cloudwatch_agent = true                 # Enables Cloudwatch agent and have metrics reported\n\n  update_route_tables = true\n  route_tables_ids = {\n    \"your-rtb-name-A\" = \"rtb-abc1234Foo\"\n    \"your-rtb-name-B\" = \"rtb-abc1234Bar\"\n  }\n}\n</code></pre> <p>It is also possible to configure fck-nat with out-of-the-box Terraform modules, but you may not be able to leverage all of fck-nat's features.</p> <pre><code>data \"aws_ami\" \"fck_nat\" {\n  filter {\n    name   = \"name\"\n    values = [\"fck-nat-al2023-*\"]\n  }\n\n  filter {\n    name   = \"architecture\"\n    values = [\"arm64\"]\n  }\n\n  owners      = [\"568608671756\"]\n  most_recent = true\n}\n\nresource \"aws_network_interface\" \"fck-nat-if\" {\n  subnet_id       = aws_subnet.subnet_public.id\n  security_groups = [aws_default_security_group.default_security_group.id]\n\n  source_dest_check = false\n}\n\nresource \"aws_instance\" \"fck-nat\" {                                                   \n  ami           = data.aws_ami.fck_nat.id\n  instance_type = \"t4g.nano\"\n\n  network_interface {\n    network_interface_id = aws_network_interface.fck-nat-if.id\n    device_index         = 0\n  }                                                                              \n}\n</code></pre>"},{"location":"deploying/#cloudformation","title":"CloudFormation","text":"<p>Note</p> <p>If you'd be interested in seeing fck-nat published on the CloudFormation registry, give this issue a +1</p> <p>For brevity, this document assumes you already have a VPC with public and private subnets defined in your CloudFormation template. This example template provisions the minimum resources required to connect fck-nat in your VPC. This is a good option for those that have an existing VPC and NAT Gateway and are looking to switch over. </p> <ol> <li>A security group allowing ingress traffic from within the VPC and egress out to the internet</li> <li>A auto scaling group that creates an EC2 instance using the fck-nat AMI</li> <li>A route in the private subnet route table directing traffic to the fck-nat instance.</li> </ol> <p>This snippet assumes the following resources are already defined:</p> <ol> <li><code>VPC</code>: An <code>AWS::EC2::VPC</code> resource.</li> <li><code>PublicSubnet</code>: An <code>AWS::EC2::Subnet</code> which has an <code>AWS::EC2::InternetGateway</code> attached.</li> <li><code>PrivateSubnetRouteTable</code>: An <code>AWS::EC2::RouteTable</code> with an <code>AWS::EC2::SubnetRouteTableAssociation</code> to a <code>AWS::EC2::Subnet</code></li> </ol> <p>Steps to deploy:</p> <ol> <li>Paste your VPC ID, public subnet ID, VPC CIDR block into the parameters. Set the FckNatAMIParameter based on the region fck-nat is deployed to.</li> <li>Deploy with CloudFormation <code>aws cloudformation deploy --force-upload --capabilities CAPABILITY_IAM --template-file template.yml --stack-name FckNat</code></li> <li>Add the default route to your route table on the subnet. It is best to do this manually so you can do a seamless cut over from your existing NAT gateway. Go to <code>VPC &gt; Route Tables &gt; Private route table &gt; Routes &gt; Edit Routes</code> Add a 0.0.0.0/0 route pointing to the network interface.</li> </ol> <pre><code>Parameters:\n  VpcIdParameter:\n    Type: AWS::EC2::VPC::Id\n  SubnetIdParameter:\n    Type: AWS::EC2::Subnet::Id\n  CIDRParameter:\n    Type: String\n    Default: \"10.0.0.0/16\"\n  FckNatAMIParameter:\n    Type: AWS::EC2::Image::Id\n\nResources:\n  FckNatInterface:\n    Type: AWS::EC2::NetworkInterface\n    Properties:\n      Description: FckNat Gateway Interface\n      SubnetId: !Ref SubnetIdParameter\n      GroupSet:\n        - !GetAtt [FckNatSecurityGroup, GroupId]\n      SourceDestCheck: false\n  FckNatAsgInstanceProfile:\n    Type: AWS::IAM::InstanceProfile\n    Properties:\n      Roles:\n        - !Ref FckNatRole\n  FckNatLaunchTemplate:\n    Type: AWS::EC2::LaunchTemplate\n    DependsOn: FckNatRole\n    Properties:\n      LaunchTemplateName: FckNatLaunchTemplate\n      LaunchTemplateData:\n        ImageId: !Ref FckNatAMIParameter\n        InstanceType: t4g.nano\n        NetworkInterfaces:\n          - DeviceIndex: 0\n            AssociatePublicIpAddress: true\n            Groups:\n            - !GetAtt [FckNatSecurityGroup, GroupId]\n        IamInstanceProfile:\n          Name: !Ref FckNatAsgInstanceProfile\n        UserData:\n          Fn::Base64: !Sub |\n            #!/bin/bash\n            echo \"eni_id=${FckNatInterface}\" &gt;&gt; /etc/fck-nat.conf\n            service fck-nat restart\n  FckNatAsg:\n    Type: AWS::AutoScaling::AutoScalingGroup\n    Properties:\n      MaxSize: \"1\"\n      MinSize: \"1\"\n      DesiredCapacity: \"1\"\n      LaunchTemplate:\n        LaunchTemplateId: !Ref FckNatLaunchTemplate\n        Version: !GetAtt FckNatLaunchTemplate.LatestVersionNumber\n      VPCZoneIdentifier:\n        - !Ref SubnetIdParameter\n      Tags:\n        - Key: Name\n          Value: fck-nat\n          PropagateAtLaunch: true\n    UpdatePolicy:\n      AutoScalingScheduledAction:\n        IgnoreUnmodifiedGroupSizeProperties: true\n  FckNatSecurityGroup:\n    Type: AWS::EC2::SecurityGroup\n    Properties:\n      GroupDescription: Security Group for FckNat\n      SecurityGroupIngress:\n        - CidrIp: !Ref CIDRParameter\n          IpProtocol: \"-1\"\n      SecurityGroupEgress:\n        - CidrIp: 0.0.0.0/0\n          Description: Allow all outbound traffic by default\n          IpProtocol: \"-1\"\n      VpcId: !Ref VpcIdParameter\n  FckNatRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        Statement:\n          - Action: sts:AssumeRole\n            Effect: Allow\n            Principal:\n              Service: ec2.amazonaws.com\n        Version: \"2012-10-17\"\n      Policies:\n        - PolicyName: AttachNatEniPolicy\n          PolicyDocument:\n            Statement:\n              - Action:\n                  - ec2:AttachNetworkInterface\n                  - ec2:ModifyNetworkInterfaceAttribute\n                Effect: Allow\n                Resource: \"*\"\n            Version: \"2012-10-17\"\n        - PolicyName: AssociateNatAddressPolicy\n          PolicyDocument:\n            Statement:\n              - Action:\n                  - ec2:AssociateAddress\n                  - ec2:DisassociateAddress\n                Effect: Allow\n                Resource: \"*\"\n            Version: \"2012-10-17\"\n</code></pre>"},{"location":"deploying/#manual-web-console","title":"Manual - Web Console","text":"<p>The following instructions can be used to deploy the fck-nat AMI manually. **Summary: **  1. Launch fck-nat AMI 2. Modify ENI to disable source/dest check 3. Modify the private route table, default route to fck-nat target 4. Validate</p> <p>NOTE: The following example uses fck-nat AMI version 1.2.0 for arm64 on t4g.nano.</p>"},{"location":"deploying/#ec2-instance-launch","title":"EC2 Instance Launch","text":"<ol> <li>Visit the EC2 service in your preferred region: EC2 Link</li> <li>Click Launch Instances </li> <li>Give the instance a name </li> <li>Search for AMIs owned by \"568608671756\"    </li> <li>Select the ARM64 1.2.0 fck-nat AMI </li> <li>Select Instance Type t4g.nano </li> <li>Modify Network Settings  </li> <li>Select VPC  </li> <li>Place in public subnet, ensure Public IP is assigned  </li> <li>Attached Security group that permits        inbound: entire VPC CIDR inbound, all traffic        outbound: 0.0.0.0/0, all traffic </li> <li>Leave Storage at 2GB </li> <li>Review and launch </li> </ol> <p>Wait for Launch</p>"},{"location":"deploying/#modify-ec2-network-interface","title":"Modify EC2 Network Interface","text":"<p>We must modify the ENI attached to the newly launched instance to disable source/destination checks, this allows us to route through (actually hairpinning) the instance. 1. Click on the ENI of the instance  2. Select ENI, Click Actions -&gt; Change source/dest. check  3. Disable Source/Dest check and Save </p>"},{"location":"deploying/#modify-vpc-routing-table","title":"Modify VPC Routing Table","text":"<p>The VPC routing table associated with your private subnets must be modified to route traffic matching the default route to the new fck-nat instance. 1.  Open the VPC Service, Route Tables  2. Open the private route table, edit routes  3. Add a default route, target: fck-nat instance </p>"},{"location":"deploying/#validate","title":"Validate","text":"<p>Log into an instance in a private subnet and validate the external IP is the public IP assigned to your fck-nat instance.  </p> <p> </p>"},{"location":"features/","title":"fck-nat Features","text":"<p>Heads up!</p> <p>The easiest way to get all of the features below is to use the official CDK or Terraform modules!</p>"},{"location":"features/#high-availability-mode","title":"High-availability Mode","text":"<p>fck-nat can operate on a single instance, or within an autoscaling group for improved availability. When running in an autoscaling group, fck-nat can be configured to always attach a specific ENI at start-up, allowing fck-nat to maintain a static internal-facing IP address. (For information on static external IPs, see: Static IP)</p> <p>This feature is controlled via the <code>eni_id</code> directive in the configuration file and also requires additional IAM permissions to function, see: IAM Requirements</p>"},{"location":"features/#static-ip","title":"Static IP","text":"<p>If you wish for your NAT instance to maintain a consistent external facing IP, fck-nat supports automatically association of an Elastic IP (EIP) addresss at launch.</p> <p>This feature is controlled via the <code>eip_id</code> directive in the configuration file and also requires additional IAM permissions to function, see: IAM Requirements</p>"},{"location":"features/#ssm-agent","title":"SSM Agent","text":"<p>The Amazon SSM Agent is installed in the fck-nat AMI by default to allow SSH-less access to instances as well as automated patching capabilities if you so choose (The fck-nat AMI also has kernel live patching modules enabled). To enable access via SSM, you just need to make sure that your fck-nat instance has the requisite IAM permissions attached</p>"},{"location":"features/#metrics","title":"Metrics","text":"<p>One of the objectives of fck-nat is to offer as close as possible metric parity with Managed NAT Gateway. While the project supports various metrics similar to the managed NAT Gateway via Cloudwatch agent, each provider is responsible for passing their configuration to the agent via fck-nat's <code>cwagent_enabled</code>, and <code>cwagent_cfg_param_name</code> directives within its configuration file.</p> <p>As an example, you might use the following configuration file which have Cloudwatch agent report most of metrics provided in the managed NAT Gateway:</p> <pre><code>{\n  \"agent\": {\n    \"metrics_collection_interval\": 60,\n    \"run_as_user\": \"root\",\n    \"usage_data\": false\n  },\n  \"metrics\": {\n    \"namespace\": \"fck-nat\",\n    \"metrics_collected\": {\n      \"net\": {\n        \"resources\": [\"ens5\", \"ens6\"],\n        \"measurement\": [\n          { \"name\": \"bytes_recv\", \"rename\": \"BytesIn\",  \"unit\": \"Bytes\" },\n          { \"name\": \"bytes_sent\", \"rename\": \"BytesOut\",  \"unit\": \"Bytes\" },\n          { \"name\": \"packets_sent\", \"rename\": \"PacketsOutCount\",  \"unit\": \"Count\" },\n          { \"name\": \"packets_recv\", \"rename\": \"PacketsInCount\",  \"unit\": \"Count\" },\n          { \"name\": \"drop_in\", \"rename\": \"PacketsDropInCount\",  \"unit\": \"Count\" },\n          { \"name\": \"drop_out\", \"rename\": \"PacketsDropOutCount\",  \"unit\": \"Count\" }\n        ]\n      },\n      \"netstat\": {\n        \"measurement\": [\n          { \"name\": \"tcp_syn_sent\", \"rename\": \"ConnectionAttemptOutCount\",  \"unit\": \"Count\" },\n          { \"name\": \"tcp_syn_recv\", \"rename\": \"ConnectionAttemptInCount\",  \"unit\": \"Count\" },\n          { \"name\": \"tcp_established\", \"rename\": \"ConnectionEstablishedCount\",  \"unit\": \"Count\" }\n        ]\n      },\n      \"ethtool\": {\n        \"interface_include\": [\"ens5\", \"ens6\"],\n        \"metrics_include\": [\n          \"bw_in_allowance_exceeded\",\n          \"bw_out_allowance_exceeded\",\n          \"conntrack_allowance_exceeded\",\n          \"pps_allowance_exceeded\"\n        ]\n      },\n      \"mem\": {\n        \"measurement\": [\n          { \"name\": \"used_percent\", \"rename\": \"MemoryUsed\",  \"unit\": \"Percent\" }\n        ]\n      }\n    },\n    \"append_dimensions\": {\n      \"InstanceId\": \"${aws:InstanceId}\",\n      \"AutoScalingGroupName\": \"${aws:AutoScalingGroupName}\"\n    }\n  }\n}\n</code></pre> <p>Ensure you are aware of Cloudwatch metrics costs before enabling Cloudwatch agent. The above configuration would cost you about $17/monthly, excluding free tier.  </p> <p>IAM requirements: <code>ssm:GetParameter</code> on the SSM Parameter ARN, and <code>cloudwatch:PutMetricData</code> on <code>*</code>.</p>"},{"location":"features/#nat64","title":"NAT64","text":"<p>fck-nat features NAT64 provided through jool as a mean to allow IPv6-only networks to communicate with external IPv4 networks, working seamlessly with the AWS' DNS64 feature.</p> <p>This feature is available in the NAT64-enabled AMIs (prefixed with <code>nat64-</code>) and is enabled at runtime only when jool is installed.</p>"},{"location":"limitations/","title":"Limitations","text":""},{"location":"limitations/#availability","title":"Availability","text":"<p>fck-nat has some fundamental limitations when it comes to availability. If the instance requires replacement, downtime for the ASG (when using HA mode) to bring up a new instance is ~5 minutes, but is automatic. However, due to replacement nodes effectively taking over the configured internal ENI, you can significantly reduce disruption if you launch a second instance before the first is terminated. Existing connections will be cut, but downtime will only be a few seconds.</p>"},{"location":"limitations/#security-groups-and-quota-limitations","title":"Security groups and quota limitations","text":"<p>Using security groups to firewall your NAT instances (only allowing connections from inside your VPC) are subject to conntrack limitations. You can read more about the details of those limitations here: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-connection-tracking.html</p> <p>If you're running fck-nat with additional CloudWatch monitoring enabled we report the <code>conntrack_allowance_exceeded</code> and <code>conntrack_allowance_available</code> metrics which would enable you to observe if these conntrack limits are being hit. If you're hitting these limits, it is recommended that you allow all traffic in security groups and use <code>iptables</code> in order to drop inbound connections from outside your VPC.</p>"}]}